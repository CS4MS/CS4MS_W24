{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EvzaQlIqOyXc"
      },
      "source": [
        "## Exercise 6\n",
        "\n",
        "In this homework we will try to confuse a pretrained network with crazy transformations\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ji3MQZ9KQOh7"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision as torchvision\n",
        "\n",
        "from datetime import datetime\n",
        "import datetime\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N7TnokUcOmsE"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)\n",
        "\n",
        "# Download our \"dataset\" - its really just some cat and dog images\n",
        "!wget https://github.com/CS4MS/CS4MS_S23/blob/main/images/cat.jpg\n",
        "!wget https://github.com/CS4MS/CS4MS_S23/blob/main/images/cat2.jpg\n",
        "!wget https://github.com/CS4MS/CS4MS_S23/blob/main/images/cat3.jpg\n",
        "!wget https://github.com/CS4MS/CS4MS_S23/blob/main/images/cat4.jpg\n",
        "!wget https://github.com/CS4MS/CS4MS_S23/blob/main/images/cat5.jpg\n",
        "!wget https://github.com/CS4MS/CS4MS_S23/blob/main/images/cat6.jpg\n",
        "!wget https://github.com/CS4MS/CS4MS_S23/blob/main/images/cat7.jpg\n",
        "!wget https://github.com/CS4MS/CS4MS_S23/blob/main/images/cat8.jpg\n",
        "!wget https://github.com/CS4MS/CS4MS_S23/blob/main/images/cat9.jpg\n",
        "!wget https://github.com/CS4MS/CS4MS_S23/blob/main/images/dog1.jpg\n",
        "!wget https://github.com/CS4MS/CS4MS_S23/blob/main/images/dog2.jpg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QCBGAc3VQxW-"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "\n",
        "file_names = [\"cat.jpg\", \"cat2.jpg\", \"cat3.jpg\", \"cat4.jpg\", \"cat5.jpg\", \"cat6.jpg\", \"cat7.jpg\", \"cat8.jpg\", \"cat9.jpg\", \"dog1.jpg\", \"dog2.jpg\"]\n",
        "\n",
        "def imshow(img):\n",
        "    npimg = img.numpy()\n",
        "    fig, ax = plt.subplots(figsize=(30, 30))\n",
        "    ax.axis('off')\n",
        "    ax.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "\n",
        "cats_org = []\n",
        "for i in file_names:\n",
        "  temp_im = Image.open(i)\n",
        "  cats_org.append(temp_im)\n",
        "\n",
        "cats_labels = [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1] # The value is one if there is an outlier e.g. a dog. So cat=0 and dog=1\n",
        "cats_labels = np.asarray(cats_labels)\n",
        "print(f\"cats_labels: {cats_labels}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "awTvDmueRsMS"
      },
      "outputs": [],
      "source": [
        "norm_mean = (0.485, 0.456, 0.406)\n",
        "norm_std = (0.229, 0.224, 0.225)\n",
        "\n",
        "# Standard transform we learned in the last lecture\n",
        "cat_transform = transforms.Compose([\n",
        "                                  # resize image to the network input size\n",
        "                                  transforms.Resize((224,224)),\n",
        "                                  transforms.ToTensor(),\n",
        "                                  transforms.Normalize(norm_mean, norm_std),\n",
        "                                   ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Ka-tm6cRwxz"
      },
      "outputs": [],
      "source": [
        "# As you can see the two last pictures are not cats but dogs.\n",
        "\n",
        "cats = []\n",
        "\n",
        "for i in cats_org:\n",
        "  cats.append(cat_transform(i))\n",
        "\n",
        "imshow(torchvision.utils.make_grid(cats))\n",
        "cats_tensor = torch.stack(cats)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "23Y7mvjYScEy"
      },
      "outputs": [],
      "source": [
        "## Loading a Neural Network\n",
        "model = torchvision.models.resnet18(pretrained = False) # This is a very well known network but it is designed for 1000 classes and not just cats and dogs this is why we need the next line\n",
        "model.fc = nn.Sequential(nn.Linear(512,256),\n",
        "                         nn.ReLU(),\n",
        "                         nn.Dropout(0.2),\n",
        "                         nn.Linear(256,2),\n",
        "                         nn.LogSoftmax(dim=1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gC_trT_3FmWq"
      },
      "outputs": [],
      "source": [
        "state_dict_trained = torch.hub.load_state_dict_from_url('https://github.com/CS4MS/CS4MS_W22/raw/main/data/dogs-vs-cats.pth', map_location = device) # This is a checkpoint to a trained cat and dog model that works pretty well\n",
        "\n",
        "model.load_state_dict(state_dict_trained[\"state_dict\"]) ## Here we load the trained weights (state_dict) in our model \n",
        "model.eval() # This puts our model in eval mode"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jd35b1sESkKC"
      },
      "outputs": [],
      "source": [
        "# Lets try the model\n",
        "with torch.no_grad(): # during testing we dont learn so we dont need to calculate the gradient for learning\n",
        "  outputs=model(cats_tensor) # That is a forward pass to a network\n",
        "outputs = torch.exp(outputs) # transform the output to probabilities\n",
        "pred = torch.argmax(outputs, dim=1).cpu().numpy()  # here we take the highest probabily and get the index 0 was cat and 1 was dog\n",
        "\n",
        "# Lets checkout the predictions of the network\n",
        "print(f\"outputs: {outputs}\")\n",
        "print(f\"pred: {pred}\")\n",
        "# [0.8978, 0.1022] means that the network thinks that the true class is index 0 with a probably of (89%)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aTga3n3HSYDs"
      },
      "outputs": [],
      "source": [
        "# Lets make accuracies out of this\n",
        "acc = np.sum(cats_labels == pred, dtype=float) # here we compare the TRUE cats_labels with the PREDICTED pred and sum up how often pred was correct\n",
        "acc = acc/len(pred)  # here we divide by lenght to get the ratio between correctly classified and total amount of images\n",
        "\n",
        "print(f\"The Accuracy is {acc * 100}%\")\n",
        "# As you can see the network predicted all cats and all dogs correctly..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6BlhkwpZPsEh"
      },
      "source": [
        "# Homework\n",
        "Modify the Transformation so that the resulting accuracy drops below 100%\n",
        "This might a bit challenging. Try to find an augmentation that screws up the accuracy while we humans can still recognize the contents.\n",
        "\n",
        "Feel free to check out different augmentation libraries like albumentations : https://github.com/albumentations-team/albumentations\n",
        "\n",
        "Once your acc drops below 1.0 you can submit your homework but feel free to bring it as low as possible while you can still recognize the images."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9hcP__cyfUyq"
      },
      "outputs": [],
      "source": [
        "###### TODO START #######\n",
        "# Add or remove transformations to confuse the prediction\n",
        "confuse_transform = transforms.Compose([\n",
        "                                  # resize image to the network input size\n",
        "                                  transforms.Resize((224,224)),\n",
        "                                  transforms.ToTensor(),\n",
        "                                  transforms.Normalize(norm_mean, norm_std),\n",
        "                                   ])\n",
        "###### TODO END #######\n",
        "# Run the next cell to test your transformations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_YWNZL64Sp7k"
      },
      "outputs": [],
      "source": [
        "cats = [] # delete all previous cats\n",
        "for i in cats_org: \n",
        "  cats.append(confuse_transform(i)) # Apply transformation to each image and save it to list\n",
        "\n",
        "imshow(torchvision.utils.make_grid(cats)) # show the images\n",
        "\n",
        "cats_tensor = torch.stack(cats) # make them to a tensor (from list to tensor)\n",
        "\n",
        "with torch.no_grad(): # during testing we dont learn so we dont need to calculate the gradient for learning\n",
        "  outputs=model(cats_tensor)  # That is a forward pass to a network\n",
        "outputs = torch.exp(outputs) # transform the output to probabilities\n",
        "pred = torch.argmax(outputs, dim=1).cpu().numpy() # here we take the highest probabily and get the index 0 was cat and 1 was dog\n",
        "acc = np.sum(cats_labels == pred, dtype=float) # here we compare the TRUE cats_labels with the PREDICTED pred and sum up how often pred was correct\n",
        "acc = acc/len(pred) # here we divide by lenght to get the ratio between correctly classified and total amount of images\n",
        "\n",
        "print(f\"outputs: {outputs} \\n The Accuracy is {acc * 100}%\" )\n",
        "\n",
        "if acc < 1.0:\n",
        "  homework_done = True\n",
        "  homework_acc = acc\n",
        "  print(f\"Homework done with acc: {homework_acc}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "I1a6NpAwiJ-u"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "interpreter": {
      "hash": "62f47e0a940d9130cb9d8ad31b00082fdc26fbada418265db41289562a6ad16c"
    },
    "kernelspec": {
      "display_name": "Python 3.8.10 ('default')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
